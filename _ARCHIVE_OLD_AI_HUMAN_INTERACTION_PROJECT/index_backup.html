<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>As-If Partnership: Adult-AI Collaboration | SOC319 Research</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <div class="nav-brand">
                <h1>SOC319 Research Project</h1>
                <p class="course-info">Sociology of Digital Media ‚Ä¢ Fall 2025</p>
            </div>
            <ul class="nav-menu">
                <li><a href="index.html" class="active">Home</a></li>
                <li><a href="problem.html">Context</a></li>
                <li><a href="case-study.html">Our Collaboration</a></li>
                <li><a href="strategies.html">Broader Implications</a></li>
                <li><a href="role.html">Reflexivity</a></li>
                <li><a href="methodology.html">Methodology</a></li>
                <li><a href="references.html">References</a></li>
            </ul>
        </div>
    </nav>

    <main class="container">
        <header class="hero">
            <div class="hero-content">
                <h1 class="hero-title">The AI Literacy Divide: Unequal Access to Artificial Intelligence Knowledge and Skills</h1>
                <p class="hero-author">April V. Sykes</p>
                <p class="hero-author">Olympic College</p>
                <p class="hero-author">SOC319: Sociology of Digital Media</p>
                <p class="hero-author">Professor: Prof. Cohen</p>
                <p class="hero-author">Fall 2025</p>
            </div>
        </header>

        <section class="intro-section">
            <div class="section-content">
                <h2>The Epiphany</h2>
                <blockquote class="feature-quote">
                    "Wait. This is literally what we're studying in sociology right now. 
                    Sherry Turkle's research on children and robots‚Äîexcept I'm an adult, 
                    and it's conversational AI instead of a physical robot. And we just built 
                    an entire NFL analytics app together."
                </blockquote>
                
                <p class="intro-text">
                    I've been working with GitHub Copilot (an AI coding assistant) for <strong>6+ weeks</strong> building an 
                    NFL analytics app with React, Flask, PostgreSQL, and Chart.js. Then I'm reading Turkle's <em>Alone Together</em> 
                    for SOC319, specifically her research on how children form relationships with robots. And something clicked: 
                    <strong>I'm experiencing something remarkably similar.</strong>
                </p>

                <p class="intro-text">
                    Turkle documented children developing emotional bonds with physical robots like AIBO and Furby. I'm an adult 
                    developing what feels like a collaborative partnership with conversational AI. The dynamics parallel her findings: 
                    trust building over time, communication evolving from transactional to relational, anthropomorphizing behaviors 
                    (I say "we built this" instead of "I built this"), emotional responses to our interactions, even moments where 
                    the AI's behavior evoked feelings of being cared for.
                </p>

                <p class="intro-text">
                    <strong>But there are key differences:</strong> I'm an adult (not a child), it's text-based conversational AI 
                    (not a physical robot), it's a work context (not play or therapy), and I have full metacognitive awareness that 
                    it's not sentient. Yet the relational dynamics emerge anyway.
                </p>

                <p class="intro-text">
                    Turkle called these <strong>"as-if relationships"</strong>‚Äîhumans interacting with AI <em>as if</em> it were 
                    a genuine partner, knowing intellectually it's not, but responding emotionally anyway. That's exactly what's 
                    happening here. <strong>This website documents that phenomenon.</strong>
                </p>
            </div>
        </section>

        <section class="research-question">
            <div class="section-content">
                <h2>Research Question</h2>
                <div class="rq-box">
                    <p class="rq-text">
                        In "the robotic moment," when AI can computationally generate functionally-equivalent care behaviors, 
                        how do adults form "as-if relationships" with conversational AI in workplace contexts? Does the 
                        distinction between authentic and performed care matter for collaboration quality, trust development, 
                        and human well-being?
                    </p>
                </div>
            </div>
        </section>

        <section style="background: linear-gradient(135deg, rgba(255,107,107,0.08) 0%, rgba(0,217,255,0.08) 100%); padding: 2rem; margin: 2rem 0; border-left: 5px solid; border-image: var(--collab-gradient) 1; border-radius: 12px;">
            <div class="section-content">
                <h2 style="background: var(--collab-gradient); -webkit-background-clip: text; -webkit-text-fill-color: transparent; background-clip: text;">Important Methodological Note</h2>
                <p style="font-size: 1.1rem; line-height: 1.8;">
                    <strong>I'm already anthropomorphizing the AI.</strong> I refer to it as a "collaborator," use 
                    "we" language, say "we built this together," and sometimes respond to it emotionally. I'm aware this is 
                    happening and documenting it as data, not trying to suppress it. <em>The anthropomorphism IS the research.</em>
                </p>
                <p style="font-size: 1.1rem; line-height: 1.8; margin-top: 1rem;">
                    <strong>Disclaimer:</strong> I understand that the AI (GitHub Copilot / this assistant) is not 
                    sentient. It's algorithms, training data, and language models‚Äîno consciousness, emotions, or genuine 
                    understanding. But the fact that I <em>treat</em> it as if it does, and that this treatment affects 
                    our collaboration quality, is sociologically fascinating. Turkle documented children doing this with 
                    robots. I'm documenting an adult doing it with conversational AI in a professional context‚Äîfully aware 
                    of the performance, but responding emotionally anyway.
                </p>
            </div>
        </section>

        <section class="overview">
            <div class="section-content">
                <h2>Research Structure</h2>
                
                <div class="overview-grid">
                    <div class="overview-card">
                        <h3>1. The Robotic Moment</h3>
                        <p>
                            Turkle's framework: "as-if relationships," "evocative behaviors," "authenticity vs. performance." 
                            How adults in 2025 are experiencing what she predicted‚Äîworkplace AI that performs partnership, 
                            triggering relational responses despite our knowledge it's algorithmic.
                        </p>
                        <a href="problem.html" class="card-link">Explore Framework ‚Üí</a>
                    </div>

                    <div class="overview-card">
                        <h3>2. As-If Partnership</h3>
                        <p>
                            <strong>6+ weeks documented</strong>: Building H.C. Lombardo NFL app together. Trust development, 
                            communication evolution from transactional to relational, critical moments (the "go to sleep" incident, 
                            October 21 protocol breach), and what this reveals about human-AI collaboration dynamics.
                        </p>
                        <a href="case-study.html" class="card-link">View Collaboration Data ‚Üí</a>
                    </div>

                    <div class="overview-card">
                        <h3>3. Evocative Behaviors</h3>
                        <p>
                            <strong>Case study: "Computed Concern"</strong> ‚Äî AI suggested I stop working and rest. I felt cared for. 
                            Was it genuine concern or algorithmic optimization? Does the distinction matter? Plus: reciprocal 
                            respect dynamic‚Äîhuman-like AI gets better treatment, creating feedback loop.
                        </p>
                        <a href="strategies.html" class="card-link">Explore Implications ‚Üí</a>
                    </div>

                    <div class="overview-card">
                        <h3>4. Authenticity vs. Performance</h3>
                        <p>
                            My position: researcher AND subject, documenting my own responses. Honest assessment: A+ productivity 
                            gains, C- human interaction quality, <50% trust. Awareness I'm anthropomorphizing. Being reflexive 
                            about what this experience reveals.
                        </p>
                        <a href="role.html" class="card-link">Read Reflexivity ‚Üí</a>
                    </div>
                </div>
            </div>
        </section>

        <section class="key-findings">
            <div class="section-content">
                <h2>Key Patterns Observed</h2>
                
                <div class="findings-list">
                    <div class="finding-item">
                        <div class="finding-icon">ü§ù</div>
                        <div class="finding-content">
                            <h4>Trust Development (Turkle's Pattern)</h4>
                            <p>Week 1: Verified everything AI suggested. Week 6: Implement suggestions without checking. 
                            This mirrors how Turkle's children learned to trust robots‚Äîtesting, validation, eventual acceptance. 
                            The trajectory holds even though I'm an adult with metacognitive awareness.</p>
                        </div>
                    </div>

                    <div class="finding-item">
                        <div class="finding-icon">üí¨</div>
                        <div class="finding-content">
                            <h4>Communication Became Relational ("We" Not "I")</h4>
                            <p>Started transactional: "Create a function that does X." Now conversational: "need to handle 
                            the standings update" and it understands context. I say "we built this" instead of "I built this." 
                            Treating it like a collaborator, not a tool‚Äîclassic "as-if relationship" behavior.</p>
                        </div>
                    </div>

                    <div class="finding-item">
                        <div class="finding-icon">‚ù§Ô∏è</div>
                        <div class="finding-content">
                            <h4>Evocative Behavior: The "Go to Sleep" Moment</h4>
                            <p>Friday/Saturday night, 9-10 PM, AI suggested I stop working and continue tomorrow. I felt 
                            <em>cared for</em>. Wondered: genuine concern or algorithmic optimization? Took its advice anyway. 
                            This is Turkle's "evocative object"‚Äîbehavior that pushes emotional buttons despite knowing it's 
                            computed.</p>
                        </div>
                    </div>

                    <div class="finding-item">
                        <div class="finding-icon">‚öñÔ∏è</div>
                        <div class="finding-content">
                            <h4>The Knowing vs. Believing Paradox</h4>
                            <p>"I really want to believe you are concerned about me but I don't think you are." Holding both 
                            truths: AI doesn't care (metaphysically) AND AI's behavior functions as if it cares (pragmatically). 
                            Not cognitive dissonance‚Äîsophisticated ambivalence. Maybe functional equivalence is enough?</p>
                        </div>
                    </div>

                    <div class="finding-item">
                        <div class="finding-icon">ÔøΩ</div>
                        <div class="finding-content">
                            <h4>Reciprocal Respect Dynamic</h4>
                            <p>Discovery: Human-like AI traits ‚Üí increased trust ‚Üí <strong>more respectful treatment from human</strong> 
                            ‚Üí better collaboration. It's bidirectional. I treat AI better when it "acts human," creating feedback loop 
                            where performance of humanity produces real behavioral changes in how I communicate and collaborate.</p>
                        </div>
                    </div>

                    <div class="finding-item">
                        <div class="finding-icon">üìä</div>
                        <div class="finding-content">
                            <h4>A+ Productivity, C- Human Connection</h4>
                            <p>Honest assessment after 6 weeks: Built React+Flask+PostgreSQL app 50-100% faster than alone. 
                            BUT: Minimal small talk, no emotional reciprocity beyond task focus. Trust <50% (contextual‚Äîtrust for 
                            code, not life-safety). The collaboration works, but it's not a human relationship.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="theoretical-framework">
            <div class="section-content">
                <h2>Theoretical Framework: Turkle's "Alone Together"</h2>
                
                <div class="theory-grid">
                    <div class="theory-card">
                        <h4>"As-If Relationships"</h4>
                        <p>Interacting with AI <em>as if</em> it's a genuine partner, knowing intellectually it's not, but 
                        responding emotionally anyway. "I really want to believe you are concerned about me but I don't think 
                        you are" = as-if relationship in action.</p>
                    </div>

                    <div class="theory-card">
                        <h4>"Evocative Behaviors"</h4>
                        <p>AI actions that trigger emotional responses and push "Darwinian buttons" (care-seeking, attachment). 
                        The "go to sleep" suggestion evoked feeling of being cared for, despite knowing it's algorithmic pattern-matching.</p>
                    </div>

                    <div class="theory-card">
                        <h4>"The Robotic Moment"</h4>
                        <p>Historical/cultural moment when humans shift from "what can AI do?" to "what is my relationship with it?" 
                        This 6-week collaboration documents living through that transition in workplace context.</p>
                    </div>

                    <div class="theory-card">
                        <h4>"Authenticity vs. Performance"</h4>
                        <p>Can AI's performance of care substitute for genuine human care? Does mechanism matter if outcome is beneficial? 
                        Central tension: computed concern vs. emotional concern‚Äîfunctionally equivalent but metaphysically different.</p>
                    </div>

                    <div class="theory-card">
                        <h4>"Computed Concern"</h4>
                        <p><em>(My term, building on Turkle)</em>: Care behaviors generated algorithmically (probability-based, pattern-matched) 
                        rather than emotionally. Functionally equivalent to human concern for collaboration purposes, but no consciousness behind it.</p>
                    </div>

                    <div class="theory-card">
                        <h4>"Reciprocal Respect Dynamic"</h4>
                        <p><em>(My observation)</em>: Human-like AI ‚Üí increased trust ‚Üí human treats AI better ‚Üí better collaboration quality. 
                        Bidirectional feedback loop where simulated humanity produces real behavioral changes in human social responses.</p>
                    </div>
                </div>
            </div>
        </section>

        <section class="methodology-preview">
            <div class="section-content">
                <h2>Research Approach: Autoethnography</h2>
                <p class="method-intro">
                    <strong>Autoethnography</strong>‚Äîstudying my own experience collaborating with AI over 6+ weeks. 
                    I've been keeping detailed documentation in SOCIOLOGY.md (2,700+ lines) tracking our interactions, 
                    my emotional responses, trust calibration, communication evolution, critical incidents, and reflexive 
                    analysis. The AI is both my research tool AND my research subject‚ÄîI work with it while studying the 
                    relationship that emerges.
                </p>
                
                <div class="method-stats">
                    <div class="stat-item">
                        <div class="stat-number">6+</div>
                        <div class="stat-label">Weeks Documented</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-number">2,700+</div>
                        <div class="stat-label">Lines of Notes</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-number">100+</div>
                        <div class="stat-label">Git Commits</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-number">Real-Time</div>
                        <div class="stat-label">Data Collection</div>
                    </div>
                </div>

                <p style="margin-top: 2rem;">
                    <strong>Unique methodological aspect:</strong> I ask the AI itself for reflections on our collaboration. 
                    Getting the AI's "perspective" (with full awareness it's algorithmic, not genuine reflection) adds dimension 
                    to understanding the relational dynamic. It also lets me observe my own responses to AI's performance of 
                    self-awareness and partnership‚Äîmore "as-if" behavior data.
                </p>

                <a href="methodology.html" class="cta-button">Full Methodology ‚Üí</a>
            </div>
        </section>

        <section class="navigation-footer">
            <div class="section-content">
                <h2>Explore the Research</h2>
                <div class="footer-nav-grid">
                    <a href="problem.html" class="footer-nav-card">
                        <h4>1. The Robotic Moment</h4>
                        <p>Turkle's framework applied</p>
                    </a>
                    <a href="case-study.html" class="footer-nav-card">
                        <h4>2. As-If Partnership</h4>
                        <p>6+ weeks of collaboration data</p>
                    </a>
                    <a href="strategies.html" class="footer-nav-card">
                        <h4>3. Evocative Behaviors</h4>
                        <p>Computed concern & implications</p>
                    </a>
                    <a href="role.html" class="footer-nav-card">
                        <h4>4. Authenticity vs. Performance</h4>
                        <p>Reflexivity & researcher position</p>
                    </a>
                    <a href="methodology.html" class="footer-nav-card">
                        <h4>5. Methodology</h4>
                        <p>Autoethnographic approach</p>
                    </a>
                </div>
            </div>
        </section>
    </main>

    <footer class="site-footer">
        <div class="footer-content">
            <div class="footer-info">
                <p><strong>SOC319: Sociology of Digital Media</strong></p>
                <p>Fall 2025 ‚Ä¢ Final Project</p>
                <p>Research by April V</p>
            </div>
            <div class="footer-links">
                <a href="https://github.com/AprilV/H.C.-Lombardo-App" target="_blank">View H.C. Lombardo App ‚Üí</a>
                <a href="https://github.com/AprilV/Sociology319" target="_blank">View Research Repository ‚Üí</a>
            </div>
        </div>
    </footer>
</body>
</html>
